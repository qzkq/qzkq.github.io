<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Python最优化算法学习笔记（Gurobi）</title>
    <link href="/2022/05/19/Python%E6%9C%80%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88Gurobi%EF%BC%89/"/>
    <url>/2022/05/19/Python%E6%9C%80%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88Gurobi%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s?__biz=MzI5MTY1MzU1Mg==&amp;mid=100000291&amp;idx=1&amp;sn=b68ef91042b9cb17c1be1af2f8728eea&amp;scene=19&token=1933614188&lang=zh_CN#wechat_redirect"> 微信公众号：数学建模与人工智能</a></p><p>github地址：<a href="https://github.com/QInzhengk/Math-Model-and-Machine-Learning">https://github.com/QInzhengk/Math-Model-and-Machine-Learning</a></p><h2 id="第一章最优化算法概述"><a href="#第一章最优化算法概述" class="headerlink" title="第一章最优化算法概述"></a>第一章最优化算法概述</h2><p>1.1最优化算法简介<br>最优化算法,即最优计算方法,也是运筹学。涵盖线性规划、非线性规划、整数规划、组合规划、图论、网络流、决策分析、排队论、可靠性数学理论、仓储库存论、物流论、博弈论、搜索论和模拟等分支。<br>当前最优化算法的应用领域如下。<br>(1)市场销售:多应用在广告预算和媒体的选择、竞争性定价、新产品开发、销售计划的编制等方面。如美国杜邦公司在20世纪50年代起就非常重视对广告、产品定价和新产品引入的算法研究。<br>(2)生产计划:从总体确定生产、储存和劳动力的配合等计划以适应变动的需求计划,主要采用线性规划和仿真方法等。此外,还可用于日程表的编排,以及合理下料、配料、物料管理等方面。<br>(3)库存管理:存货模型将库存理论与物料管理信息系统相结合,主要应用于多种物料库存量的 管理,确定某些设备的能力或容量,如工厂库存量、仓库容量,新增发电装机容量、计算机的主存储器容量、合理的水库容量等。<br>(4)运输问题:涉及空运、水运、陆路运输,以及铁路运输、管道运输和厂内运输等,包括班次调度 计划及人员服务时间安排等问题。<br>(5)财政和会计:涉及预算、贷款、成本分析、定价、投资、证券管理、现金管理等,采用的方法包括统计分析、数学规划、决策分析,以及盈亏点分析和价值分析等。<br>(6)人事管理:主要涉及以下6个方面。<br>①人员的获得和需求估计。<br>②人才的开发,即进行教育和培训。<br>③人员的分配，主要是各种指派问题。<br>④各类人员的合理利用问题。<br>⑤人才的评价，主要是测定个人对组织及社会的贡献。<br>⑥人员的薪资和津贴的确定。<br>(7)设备维修、更新可靠度及项目选择和评价:如电力系统的可靠度分析、核能电厂的可靠度B风险评估等。<br>(8)工程的最佳化设计:在土木，水利、信息电子、电机、光学、机械、环境和化工等领域皆有作业研究的应用。<br>(9)计算机信息系统:可将作业研究的最优化算法应用于计算机的主存储器配置，如等候理论在不同排队规则下对磁盘、磁鼓和光盘工作性能的影响。利用整数规划寻找满足组需求档案的寻找次序，并通过图论、数学规划等方法研究计算机信息系统的自动设计。<br>(10)城市管理:包括各种紧急服务救难系统的设计和运用.如消防车、救护车、警车等分布点的设立。美国采用等候理论方法来确定纽约市紧急电话站的值班人数,加拿大采用该方法研究城市警车的配置和负责范围，以及事故发生后警车应走的路线等。此外，还涉及城市垃圾的清扫、搬运和处理，以及城市供水和污水处理系统的规划等相关问题。<br>1.2最优化算法的内容<br>最优化算法的内容包括:规划论(线性规划、非线性规划、整数规划和动态规划)、库存论、图论、排 队论、可靠性理论、对策论、决策论、搜索论等。<br>1.2.1规划论<br>1.2.2库存论<br>库存论中研究的主要问题可以概括为何时订货（补充存贮）和每次订多少货（补充多少库存）这两个问题。<br>1.2.3图论<br>1.2.4排队论<br>排队论(随机服务系统理论)主要研究各种系统的排队长度、排队的等待时间及所提供的服务等各种参数,以便求得更好的服务,它是研究系统随机聚散现象的理论。<br>排队论的研究目的是要回答如何改进服务机构或组织所服务的对象，使某种指标达到最优的问题。如一个港口应该有多少个码头、一个工厂应该有多少名维修人员等。<br>因为排队现象是一个随机现象,因此在研究排队现象时,主要采用将研究随机现象的概率论作为主要工具。此外,还涉及微分和微分方程的相关内容。排队论把它所要研究的对象形象地描述为顾客来到服务台前要求接待。如果服务台已被其他顾客占用,那么就要排队。或者服务台时而空闲、时而忙碌,那就需要通过数学方法求得顾客的等待时间、排队长度等的概率分布。<br>排队论在日常生活中的应用非常广泛,如水库水量的调节、生产流水线的安排、铁路运输的调度 电网的设计等。<br>1.2.5 可靠性理论<br>可靠性理论是研究系统故障，以提高系统可靠性问题的理论。可靠性理论研究的系统一般分为以下两类。<br>(1)不可修复系统:这种系统的参数是寿命、可靠度等，如导弹等。<br>(2)可修复系统:这种系统的重要参数是有效度，其值为系统的正常工作时间与正常工作时间加上事故修理时间之比、如一般的机电设备等。<br>1.2.6对策论<br>对策论(博弈论)是指研究多个个体或团队之间在特定条件制约下的对局中,利用相关方的策略 而实施对应策略的学科,如田忌赛马,智猪博弈就是典型的博弈论问题。<br>1.2.7决策论<br>决策论是研究决策问题的,所谓决策就是根据客观可能性,借助一定的理论、方法和工具,科学地 选择最优方案的过程。决策问题由决策者和决策域构成,而决策域则由决策空间、状态空间和结果函数构成。研究决策理论与方法的科学就是决策科学。<br>决策所要解决的问题是多种多样的,不同角度有不同的分类方法。按决策者所面临的自然状态的确定与否可分为确定型决策、不确定型决策和风险型决策,按决策所依据的目标个数可分为单目标决策与多目标决策,按决策问题的性质可分为战略决策与策略决策，以及按不同准则划分成的种种决策问题类型。不同类型的决策问题应采用不同的决策方法。<br>决策的基本步骤如下:<br>(1)确定问题,提出决策的目标;<br>(2)发现、探索和拟定各种可行方案;<br>(3)从多种可行方案中，选出最佳方案;<br>(4)决策的执行与反馈,以寻求决策的动态最优。<br>如果对方决策者也是人（一个人或一群人），双方都希望取胜，这类具有竞争性的决策称为对策或博弈型决策。构成对策问题的3个根本要素是：局中人、策略和一局对策的得失。对策问题按局中人数分类可分成两人对策或多人对策，按局中人赢得函数的代数和是否为零可分成零和对策和非零和对策,按解的表达形式可分成纯策略对策和混合策略对策,按问题是否静态形式可分成动态对策和静态对策。<br>1.2.8搜索论<br>搜索论主要研究在资源和探测手段受到限制的情况下，如何设计寻找某种目标的最优方案,并加以实施的理论和方法。</p><h2 id="第二章Python编程方法"><a href="#第二章Python编程方法" class="headerlink" title="第二章Python编程方法"></a>第二章Python编程方法</h2><p>2.1编程基础：Python语法<br>2.1.1类与实例<br>类在大部分编程语言中都是一个很重要的概念，类是面向对象编程的基础。使用函数可以实现简单功能的复用，而使用类则可以实现复杂的系统代码复用，因此通过类来模拟复杂的仿真系统。<br>举一个例子.如PPT模板可以是一个类，那么,通过修改PPT模板中的数据和文字得到新的PPT,就是实例，这个修改的过程就是实例化。又如，动物是一个类，小猫就是一个实例。<br>类由属性和方法两部分组成。如小猫是个类，其属性包括毛色、体重，方法包括抓老鼠。又如学生是个类，某个具体的同学就是实例，学生这个类的属性包括学号、身高、体重等;而学生这个类的方法就是学生能干什么，包括学习、考试等。方法就是这个类能做哪些事情，代码实现就是函数,一个函数经过固定格式的包装后就是类的方法。<br>注意:类的定义和实例化有固定的格式要求。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 定义一个类</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">cat</span>():<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, color, weight</span>):<br>        self.color = color<br>        self.weight = weight<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">catch_mice</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;抓老鼠的方法&quot;&quot;&quot;</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;抓老鼠&#x27;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">eat_mice</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;吃老鼠&quot;&quot;&quot;</span><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;吃老鼠&#x27;</span>)<br><br><br><span class="hljs-comment"># 类的实例化</span><br>my_cat = cat(<span class="hljs-string">&#x27;yello&#x27;</span>, <span class="hljs-number">10</span>)<br><br><span class="hljs-comment"># 调用类的方法</span><br>my_cat.catch_mice()<br><span class="hljs-comment"># 输出 抓老鼠</span><br><br>my_cat.eat_mice()<br><span class="hljs-comment"># 输出 吃老鼠</span><br><br><span class="hljs-comment"># 查看类的属性</span><br><span class="hljs-built_in">print</span>(my_cat.color)<br><span class="hljs-comment"># 输出 yello</span><br><br><span class="hljs-built_in">print</span>(my_cat.weight)<br><span class="hljs-comment"># 输出 10</span><br></code></pre></td></tr></table></figure><p>所有的类都有一个_init_(self)初始化方法，用来定义类有哪些属性，也可以用来在实例化类时执行某些方法。<br>2.2Pandas基础<br>2.2.1Pandas基础数据结构<br>Pandas提供了Series和DataFrame两种基础数据结构，其中Series表示序列数据，DataFrame表示表格数据，且是由多个Series组成的。<br>2.2.2分组统计<br>Pandas的分组统计使用groupby函数，参数as_index&#x3D;False表示统计后返回DataFrame类型的结果，否则返回Series类型的统计结果。<br>2.2.3apply函数<br>对于apply函数，其作用是对目标集合中的每一个元素执行相同的操作。</p><h2 id="第三章-Gurobi优化器"><a href="#第三章-Gurobi优化器" class="headerlink" title="第三章 Gurobi优化器"></a>第三章 Gurobi优化器</h2><p>3.1Gurobi的数据结构<br>3.1.1Multidict<br>Multidict，即复合字典，就是多重字典的意思，multidict函数允许在一个语句中初始化一个或多个字典。<br>3.1.2Tuplelist<br>Tuplelist，即元组列表，就是tuple和list的组合，也就是list元素的tuple类型，其设计目的是为了高效的在元组列表中构建子列表。<br>3.1.3Tupledict<br>Tupledict是Python的dict的一个子类,通过tupledict可以更加高效地操作Gurobi中的变量子集，也就是说当定义了很多变量,需要对其中一部分变量进行操作时，可以使用tupledict的内置方法来高效轻松地构建线性表达式,如sum和prod。tupledict的键在内部存储格式是tuplelist,因此可以使用tuplelist的select方法选择集合的子集。在实际使用中,通过将元组与每个Gurobi变量关联起来,可以有效地创建包含匹配变量子集的表达式。<br>3.2 <strong>Gurobi</strong>的参数和属性<br>3.2.1参数类型<br>(1)Termination停止参数，用于控制求解的停止条件。如TimeLimit设定整个求解过程耗时限制; SolutionLimit设定MIP可行解数量; BarlterLimit设定障碍法(Barrier)迭代次数限制;IterationLimit设定单纯形法迭代次数限制，如表3.1所示。<br>(2)Tolerances容差参数，用于控制结果的精度，在大多数情况下，这个限制是通过数值公差来管理的；如果冲突小于相应的公差，求解器将结果视为满足约束。<br>(3)Simplex单纯形参数，用于控制单纯形法的应用。如InfUnbdInfo控制是否生成不可行或无界模型的附加信息。<br>(4)Barrier障碍法参数，用于控制障碍法的操作，障碍法也称罚函数法。如QCPDual控制是否获取二次模型的对偶值。<br>(5)MIP混合整数规划参数，用于控制混合整数规划算法。如BranchDir用于设定分支割平面搜索方向，默认值是自动选择的。值为-1时将总是首先探索向下分支，而值为1时则始终首先探索向上分支;Heristics设定启发式算法求解所花费的时间所占的比重。<br>(6)MIP Cuts割平面参数，用于控制割平面的形式。如Cuts用于控制全局割平面法的强度。<br>(7)Tuning调参参数，用于控制求解器的调参行为。如TuneCriterion可设定调参的准则，TuneTimeLimit可设定调参的时间。<br>(8)Multiple Solutions多解参数，用于修改MIP的搜索行为，用于尝试为MIP模型寻找多个解。如PoolSolutions决定储存可行解的数量。<br>3.2.2修改参数<br>对于Gorubi参数的修改有3种方法:一种是selPeram( paramname, newvalue)方法,其中paramname还有两种方法，一种是参数的字符串，比如”TimeLimit”，一种是完整的类属性，比如”gkb.CRB. param.TimeLimit” ;第三种方法是直接修改类的属性，写法是modelLParame.xx。<br>3.2.3属性类型<br>通过属性(Attributes)能够控制模型(变量、约束、目标等对象)的特征, Curobi中的属性共分成8种类型,分别是模型属性、变量属性、线性约束属性、SOS约束属性、二次约束属性、广义约束属性、解的质量属性和多目标属性。<br>(1)Model Attributes（模型属性),包括ModelSense模型优化方向(最大化或最小化).0bjVal当 的目标值。<br>3.2.4查看修改属性<br>查看和修改Gurobi参数属性的方法很简单,用于查看属性的函数是getAttr(attrname,objs),用于修改属性的函数是setAttr(attrname,newvalue）。<br>注意:并不是所有属性都能进行修改,对于只读属性就只能查看而不能修改。<br>(1)查看属性。<br>方法:getAttr(attrname,objs),其中attrname是属性名称,objs(可选）是列表或字典对象用来存储查询的值。<br>例如,model.getAttr(GRB.Attr.ObjVal）或简写为model.ObjVal。<br>（2)修改属性。<br>方法:setAttr(attrname,newvalue),其中attrname是属性名称,newvalue是属性的值。<br>例如, var.setAttr(GRB.Attr.VType,’C’)或简写为var.Vtype &#x3D;‘C’。<br>3.3 Gurobi线性化技巧<br>添加广义约束有两种方法;一种是model类的方法add_XXX;另一种是model.addConstr方法。约束条件用Gurobi内置函数表示.即用gurobipy.XXX函数来表达广义约束。<br>注意:当使用第二种方法时.该约束做的是逻辑判断,而不是赋值操作,这样就和model.addConstr方法的输入要求一致了。<br>3.4 Gurobi 多目标优化<br>在Gurobi中，可以通过MdelsetobjectiveN函数来建立多目标优化模型，多目标的setObjectiveN函数和单目标的setObjecive函数用法基本一致，不同的是多了目标优先级、目标劣化接受程度多目标的权重等参数。<br>setobjectiveN(expr, index, priority, weight, abstol, reltol, name)<br>各参数说明如下。<br>(1)expr:目标函数表达式，如x+ 2y + 3z。<br>(2)index:目标函数对应的序号(0,1,2,..),即第几个目标，注意目标函数序号应从0开始。<br>(3)prority:优先级,为整数，值越大表示目标优先级越高。<br>(4)weight:权重(浮点数)，在合成型多目标解法中使用该参数，表示不同目标之间的组合权重。<br>(5)abtol:允许的目标函数值最大的降低量abstol(浮点数)，即当前迭代的值相比最优值的可接受劣化程度。<br>(6)reltol:abstol的百分数表示，如rlol&#x3D;0.05则表示可接受劣化程度是5%。<br>(7)name:目标函数名称。<br>需要注意的是，在Gurobi的多目标优化中，要求所有的目标函数都是线性的，并且目标函数的优化方向应一致，即全部最大化或全部最小化，因此可以通过乘以-1实现不同的优化方向。<br>当前Gurobi支持3种多目标模式，分别是Blend（合成型)、Hierarchical(分层型)、两者的混合型。<br>Blend通过对多个目标赋予不同的权重实现将多目标转化成单目标函数，权重扮演优先级的角色<br>Herchial有优先级，一般理解是在保证第一个目标值最优的情况下优化第二个目标,或者在优 化第二个目标时要保证第一一个目标的最优值只能允许少量劣化。<br>3.5callback函数<br>callback函数的主要作用是为了获取程序运行过程中的一些中间信息，或者在程序运行过程中动态修改程序运行状态，如用户有时在求解过程中需要实现一些功能，包括终止优化、添加约束条件(割平面)、嵌入自己的算法等。<br>3.5.1回调函数callback定义<br>回调函数callback的定义的方法如下。<br>def funeion_name (model, where):<br>print(‘dosomething where gurobi run’，<br>其中calback函数有两个固定的参数:model是指定义的gurobi.Model类，where是指回调函数的出发点。<br>在callback函数使用过程中,需要注意的是where和what，即在什么地方(where)获取哪些信息(what)，如下面的代码,cbGet查询获取优化器的指定信息,即grb.CRB.Callback.MULTIOBJ_OBJCNT当 前解的数量。<br>if where -&#x3D;grb.GRB.Callback.MULTIOBJ:# where<br>print(model.cbGet(grb.GRB.Callback.MULTIOBJ_OBJCNT)) # what<br>注意:where和what一般是配套使用的,如当where&#x3D;MIP时,what只能获取MIP的相关信息。<br>3.5.2callback函数的功能<br>在Gurobi中除cbGet函数外还有一些常用函数用于获取运行过程中信息或修改运行状态,包 cbGetNodeRel.cbGetSolution ,cbCut ,cbLazy ,cbSetSolution ,cbStopOneMultiObj等。<br>cbGet(what)这个函数的使用最为频繁,常用于查询求解过程中的一些信息，如目标值、节点数等,使用时应注意what与where的匹配。</p><h2 id="第四章-线性规划"><a href="#第四章-线性规划" class="headerlink" title="第四章 线性规划"></a>第四章 线性规划</h2><p>4.1线性规划的标准型<br>在线性规划求解方法中,模型的标准形式如下。<br>(1)目标函数求最大值。<br>(2)约束条件为等式约束。<br>(3)约束条件右边的常数项大于或等于0。<br>(4)所有变量大于或等于0。<br>对于非标准形式的模型,约束方程可以通过引人松弛变量使约束不能转化成等式约束。在某一些模型中,如果目标函数是求最小值,则两边乘以-1将求min转成求max;如果遇到约束方程右边常 数项为负数,则将约束方程乘以-1使常数项非负;如果变量x没有约束,则既可以是正数也可以是负数。<br>将模型转换成标准型后，就可以使用经典的线性规划方法求解了,包括单纯形法、内点法等。<br>内点法和单纯形法的结果相差可能很大，这是因为内点法的搜索路径是在可行域内部,而不能在可行域的边界上，这也是内点法的局限性。<br>内点法不仅局限在线性规划上，二次规划等也是可以求解的,因为其本质是利用函数梯度求最优值，这同很多机器学习算法的思路是一致的，真正的难点在于如何保证新的目标函数是否存在一阶导数和二阶导数，以及如何得到一阶导数和二阶导数的信息，有了导数信息，很多工具如Python中SciPy库的optimize包就可以利用函数的一阶导数和二阶导数快速求解函数的最优值。此外，初始迭代点的选择也是很重要的，在线性规划问题中能够保证最后得到的是最优解，而非线性规划问题中，函数是非凸的，因此很难保证最后的解是全局最优解。<br>4.2列生成法<br>列生成法是一种用于求解大规模线性优化问题非常高效的算法，本质上，列生成算法就是单纯形法的一种形式，它是用来求解线性规划问题的，所不同的是列生成法改善了大规模优化问题中单纯形法基变换计算效率低的问题，列生成法在整数规划中已经得到了广泛应用。<br>4.3对偶问题<br>可以将原问题和对偶问题看成是一个问题的两个视角，如在一定的资源下如何安排生产才能使利润最大，这个问题的另一个角度就是怎样购买这些生产资源使花钱最少。从数学的角度来说，如果原问题不好求解，可以尝试从对偶问题的角度出发求原问题，如在求最小问题中，对偶问题就是寻找原问题目标函数的下界。<br>4.4拉格朗日乘子法</p><h2 id="第五章-整数规划"><a href="#第五章-整数规划" class="headerlink" title="第五章 整数规划"></a>第五章 整数规划</h2><p>通常默认变量的取值是大于或等于0的自然数,然而在许多实际问题中，都要求决策变量的取值为正整数，如机器台数、商品数量、工人数量、装载货物的汽车数量等，,这类要求变量为整数的问题称为整数规划(nteger Programming,IP)问题。如果只要求一部分决策变量取整数，则称为混合整数规划(Mix Integer Programming,MIP)。如果决策变量的取值只能是0或1，则称为0-1整数规划(Binary Integer Programming ,BIP)。如果模型是线性模型，则称为整数线性规划(Integer Linear Programming, ILP)。<br>求解整数规划的常用方法有分支定界法和割平面法，这两种方法的共同特点是，在线性规划的基础上，通过增加附加约束条件，使整数最优解称为线性规划的一个极点(可行域的一个顶点)，于是就可以用单纯形法等方法找到这个最优解，它们的区别在于约束条件的选取规划和方式不同。</p><h2 id="第六章-多目标优化"><a href="#第六章-多目标优化" class="headerlink" title="第六章 多目标优化"></a>第六章 多目标优化</h2><p>多目标优化(Multiobjective Optimization Problem, MOP)也叫多目标规划，即同时优化多个目标的规划问题。前面讲的都是单目标规划方法,但是在实际生活中，很多决策往往是多目标决策，如购买商品时，既要保证质量，也要价格合适,如果有赠品就更好了。那么，在企业的生产管理中，既希望利润最大化，也希望成本最小化。<br>在讲Gurobi求解多目标决策时,已经介绍了Curobi求解多目标规划的两种方法:一种是合成型.将多目标转化成单目标决策问题;另一种是分层型,在保证第一目标的情况下，尽量优化第二,第三等目标。<br>因此,多目标规划一般有两种方法:一种是化多为少,即将多目标转化为比较容易求解的单目标规划方法;另一种是分层序列法,即把目标按其重要性排序,每次都在前一个目标最优解集内求解下一个目标的最优解,直到求出共同的最优解。那么,如何理解目标最优解集呢?在多目标规划中往往有多个最优解同时满足约束条件,不同的解之间不能简单通过大小来比较,这点是同单目标规划的最大区别,多个解组成的集合称为帕累托最优解集,组成的超平面称为帕累托前沿。</p><h2 id="第七章-动态规划"><a href="#第七章-动态规划" class="headerlink" title="第七章 动态规划"></a>第七章 动态规划</h2><p>动态规划(Dynamic Programming,DP)是运筹学的一个分支，是解决多阶段决策过程最优化的一种方法。它把多变量复杂决策的问题进行分阶段决策,可高效求解多个单变量的决策问题。动态规划在现代企业管理、工农业生产中有着广泛的应用，许多问题用动态规划处理，比用线性规划或非线性规划处理更加有效,如最短路径、设备维修换新、多阶段库存等问题。<br>7.1 多阶段决策问题<br>有这样一类问题，它可以从时间或空间t将决策的过程分解为若干个相互联系的阶段.每个阶段都需要做出决策，当前阶段的决策往往会影响到下个阶段的决策,将各阶段的决策构成一个决策序列、称为策略。每个阶段都有若干个决策可供选择,因此就有许多策略可以选择。如何在这些策略中选择一个最优策略，这类问题就是多阶段决策问题。<br>一个较常见的多阶段决策问题是网络最短路径问题，给定的一个网路，需要从A出发到达D,如何选择路径才能使总路程最短，显然这是个4阶段决策问题。<br>动态规划的另一个常见例子是背包问题，一个背包最多能放15kg的物品，每个物品的重量和价值都已经知道，那要选择哪些物品才能使背包内的物品总价值最大?背包问题可以看成是一个多阶段规划问题，如果选择物品A,占用的空间将使得其他可供选择的物品减少。虽然简单背包问题可以用整数规划方法求解，但是用动态规划方法求解更为高效。</p><h2 id="第八章-图与网络分析"><a href="#第八章-图与网络分析" class="headerlink" title="第八章 图与网络分析"></a>第八章 图与网络分析</h2><p>8.1图的基本概念<br>在算法最优化领域，图与网络分析是一个很重要的组成部分，特别是在交通运输领域中，问题会被建模成一个图优化问题。不仅仅是交通问题可以用图的模型表示，像人物关系图谱、任务流程依赖关系、电力线网、信息网络等都可以用图来表示。<br>8.2最小生成树<br>在数学建模中,如果用图的数据结构求解比较麻烦,而用树的数据结构求解比较简单时,就会用到最小生成树,将图转成树来建模。在实际问题中,一个经典的案例就是村庄架设电话线问题，假设6个村庄,网络边的权值标志村庄之间的距离,现在需要架设一条电话线构造成通信网,使每个村庄都能相互通信,且电话线的总长度最小。这同最短路径TSP问题有点相似,不同的是,在最短路径问题中,每个节点只能访问一次,而在村庄电话线问题中,有些节点是可以被访问多次的。<br>8.3网络最大流问题<br>研究网络通过的流量也是生产管理中经常遇到的问题,如交通干线车辆最大通行能力.生产流水线产品最大加工能力、供水网络中最大水流量等。这类网络的弧有确定的容量(Capacity) ,虽然常用cij表示从节点i到节点j的弧最大流量,但实际上通过该弧的流量不一定能达到最大流量,因此常用fij表示通过弧的实际流量。<br>对于网络最大流研究的两个问题:一个是从网络的起点出发到网络终点所能达到的最大流量;另一个问题是,当求解网络最大流量后,分析限制网络流量最大化的关键弧,通过某些方法增加该弧的容量,使网络最大化流量增加更多。<br>8.4 VRP问题<br>VRP( Vehicle Routing Problem,车辆路径问题)是TSP问题的扩展，是交通物流领域的研究热点。这里以物流配送场景为例介绍VRP问题。某配送中心对一定区域内的客户(需求点)进行货物配送服务.每个客户的货物配送量小于车辆最大装载量，且每个客户距离配送中心，以及各个客户间的距离是已知的，通常不存在只需要一辆车跑一趟就能满足全部客户的配送需求，否则VRP就退化为TSP问题，一般来说，需要几辆车或一辆车跑多趟才能满足全部客户的配送需求。此时需要解决的问题有以下两点。<br>(1)哪些客户的货物应该分配到同一辆车上。<br>(2)每辆车对客户服务的次序是什么。<br>VRP问题是运筹优化中一类普遍又重要的问题,Google开源的运筹优化求解器Ortools针对这类问题有专门的调用接口,前面提到的VRP问题就是车辆容量限制的CVRP问题,如果是时间窗约束,如寄快递会指定快递员上门取件的时间段,这就是时间窗口约束的VRP问题,即VRPTW。在配货场景中,因仓库装卸能力有限,只能同时对两辆车进行装卸,那么其他车就需要等待前面的车装卸完成。相似的场景还有飞机场的飞机调度问题,由于飞机场的机位是有限的,如何安排飞机的起降时间和顺序就显得尤为重要,这类问题是资源约束的VRP问题,即VRRC。这些类常见问题Ortools提供了现成的解决方案。</p><h2 id="第九章-智能优化算法"><a href="#第九章-智能优化算法" class="headerlink" title="第九章 智能优化算法"></a>第九章 智能优化算法</h2><p>常见的智能优化算法有遗传算法、粒子群算法、模拟退火算法、禁忌搜索算法、蚁群算法、差分进化算法等。</p>]]></content>
    
    
    <categories>
      
      <category>数学建模</category>
      
    </categories>
    
    
    <tags>
      
      <tag>最优化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2021年MathorCup高校数学建模挑战赛b题：三维团簇的能量预测（三等）</title>
    <link href="/2022/05/19/2021%E5%B9%B4MathorCup%E9%AB%98%E6%A0%A1%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E6%8C%91%E6%88%98%E8%B5%9Bb%E9%A2%98%EF%BC%9A%E4%B8%89%E7%BB%B4%E5%9B%A2%E7%B0%87%E7%9A%84%E8%83%BD%E9%87%8F%E9%A2%84%E6%B5%8B%EF%BC%88%E4%B8%89%E7%AD%89%EF%BC%89/"/>
    <url>/2022/05/19/2021%E5%B9%B4MathorCup%E9%AB%98%E6%A0%A1%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E6%8C%91%E6%88%98%E8%B5%9Bb%E9%A2%98%EF%BC%9A%E4%B8%89%E7%BB%B4%E5%9B%A2%E7%B0%87%E7%9A%84%E8%83%BD%E9%87%8F%E9%A2%84%E6%B5%8B%EF%BC%88%E4%B8%89%E7%AD%89%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s?__biz=MzI5MTY1MzU1Mg==&mid=100000468&idx=1&sn=78ed3ca71b09e0ad39ab73f30943bdf0&scene=19#wechat_redirect">微信公众号：数学建模与人工智能</a></p><p><a href="https://github.com/QInzhengk/Math-Model-and-Machine-Learning">https://github.com/QInzhengk/Math-Model-and-Machine-Learning</a></p><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>团簇可以分为金属团簇和非金属团簇，由于金属团簇具有良好的催化性能，因此备受关注。但由于团簇的势能面过于复杂，同时有时候还需要考虑相对论效应等，所以搜索团簇的全局最优结构显得尤为困难。其中，传统的理论计算方法研究效率较低且非常耗时。因此，需要对这种方法加以改进，例如：考虑全局优化算法，结合机器学习等方法，训练团簇结构和能量的关系，从而预测新型团簇的全局最优结构，有利于发现新型团簇材料的结构和性能。本文根据团簇数据样本，通过机器学习和优化算法以及软件编程，对其数据进行处理和预测搜索，完成了以下几方面的问题：<br><strong>针对问题一</strong>，首先，通过Python编程读取xyz文件将其整合，并求出原始数据平均值对缺失的155号数据进行填充。通过金团簇Au20的原子坐标、原子数目和团簇能量来预测金团簇能量，利用库伦矩阵和特征值提取转换成向量以满足机器学习算法，然后利用K近邻回归模型、随机森林回归模型、LightGBM回归模型算法对金团簇能量进行预测，通过MSE评价指标选取最优算法为LightGBM回归模型。最后利用粒子群优化算法与其结合搜索和预测出金团簇Au20的全局最优结构的能量为-1558.381512。<br><strong>针对问题二</strong>，首先，根据金团簇Au20的结构，通过Monte Carlo方法和L-J势函数模拟生成异构体Au32的结构，重新训练LightGBM回归模型，然后利用基于LightGBM回归的粒子群优化算法预测出全局最优结构的能量为-2484.139072。通过分析团簇的对称性以及平均键合能、一级解离能和二级解离能确定结构相对稳定。<br><strong>针对问题三</strong>，同问题一，首先通过Python编程读取xyz文件将其整合，利用库伦矩阵和特征值提取转换成向量以满足机器学习算法且保证原始数据不丢失，然后利用随机森林回归模型、LightGBM回归模型算法对硼团簇能量进行预测，并且对两种模型进行网格搜索找到最优参数，来达到整体模型的偏差和方差的大和谐，通过MSE评价指标选取最优算法为随机森林回归模型。最后利用粒子群优化算法与其结合，搜索和预测出硼团簇B45-的全局最优结构的能量为-114059.5529096。<br><strong>针对问题四</strong>，通过Python编程首先对硼团簇B45-的坐标通过排列组合列出40个坐标所有情形共有 个，然后根据L-J势能函数计算所有情形的势能，取势能最低的作为B40-的坐标。最后通过B40-的坐标训练随机森林回归模型，利用基于随机森林回归模型的粒子群优化算法找到硼团簇B40-的全局最优结构的能量为-101138.961718，最后分析稳定性较为稳定且比B45-稳定。<br><strong>关键词：团簇；LGB回归模型；随机森林回归模型；蒙特卡洛；粒子群优化算法</strong></p><h1 id="一、问题重述1"><a href="#一、问题重述1" class="headerlink" title="一、问题重述1"></a>一、问题重述1</h1><p><a href="https://mp.weixin.qq.com/s?__biz=MzI5MTY1MzU1Mg==&mid=100000468&idx=1&sn=78ed3ca71b09e0ad39ab73f30943bdf0&scene=19#wechat_redirect">更新时间：2022&#x2F;4&#x2F;13</a></p><h1 id="二、问题的分析1"><a href="#二、问题的分析1" class="headerlink" title="二、问题的分析1"></a>二、问题的分析1</h1><p><strong>问题一的分析</strong>:问题一要求通过附件给出的1000个金团簇Au20的结构，建立金团簇能量预测的数学模型，并预测金团簇Au20的全局最优结构，描述形状。首先，观察所给原始数据，发现155号数据缺失，通过计算原始数据平均值对缺失值进行填补。其次，为满足机器学习算法的向量输入需求，通过库伦矩阵等方法将原子坐标进行转换，利用机器学习算法得到金团簇预测模型。最后，结合粒子群优化算法搜索和预测金团簇Au20的全局最优结构并画出图形。<br><strong>问题二的分析</strong>：问题二要求在问题一的基础上设计算法，产生金团簇不同结构的异构体，自动搜索和预测金团簇Au32的全局最优结构，并描述其几何形状，分析稳定性。用Monte Carlo方法及L-J势函数模拟金团簇Au20异构体Au32的生成。并用基于LightGBM回归的粒子群优化算法搜索和预测金团簇Au32的全局最优结构并画出图形。通过分析团簇的对称性以及平均键合能、一级解离能和二级解离能分析其稳定性。<br><strong>问题三的分析</strong>：问题三要求通过附件给出的3751个硼团簇B45-的结构，建立硼团簇能量预测的数学模型，并预测硼团簇B45-的全局最优结构，描述形状。同问题一为满足机器学习算法的向量输入需求，通过库伦矩阵等方法将原子坐标进行转换，利用机器学习算法得到硼团簇预测模型。最后，结合粒子群优化算法搜索和预测硼团簇B45-的全局最优结构并画出图形。<br><strong>问题四的分析</strong>：问题四要求在问题三的基础上设计算法，产生硼团簇不同结构的异构体，自动搜索和预测硼团簇B40-的全局最优结构，并描述其几何形状，分析稳定性。首先对硼团簇B45-的坐标通过排列组合列出40个坐标所有情形，根据势能函数计算所有情形的势能[1]，取势能最低的作为B40-的坐标。最后通过B40-的坐标训练模型，利用基于随机森林回归模型的粒子群优化算法找到硼团簇B40-的全局最优结构并画出图形。通过分析团簇的对称性以及平均键合能、一级解离能和二级解离能分析其稳定性。</p><h1 id="三、模型假设2"><a href="#三、模型假设2" class="headerlink" title="三、模型假设2"></a>三、模型假设2</h1><p>（1）数据样本中不存在不精确数据。<br>（2）团簇在空间中的平移或旋转都不会影响基于原子坐标的能量预测模型。<br>（3）使用原子直接的距离来描述体系的结构适用于当前团簇原子规模。<br>（4）基于原子坐标的机器学习模型可以一定程度上描述体系的对称性。</p><h1 id="四、符号说明2"><a href="#四、符号说明2" class="headerlink" title="四、符号说明2"></a>四、符号说明2</h1><h1 id="五、模型的建立与求解3"><a href="#五、模型的建立与求解3" class="headerlink" title="五、模型的建立与求解3"></a>五、模型的建立与求解3</h1><h2 id="5-1-问题一：金团簇能量预测模型的建立和Au20全局最优结构的预测3"><a href="#5-1-问题一：金团簇能量预测模型的建立和Au20全局最优结构的预测3" class="headerlink" title="5.1 问题一：金团簇能量预测模型的建立和Au20全局最优结构的预测3"></a>5.1 问题一：金团簇能量预测模型的建立和Au20全局最优结构的预测3</h2><h3 id="5-1-1求解思路3"><a href="#5-1-1求解思路3" class="headerlink" title="5.1.1求解思路3"></a>5.1.1求解思路3</h3><p>首先，通过Python编程读取xyz文件将其整合，并求出原始数据平均值对缺失的155号数据进行填充。由于原始数据中只包含金团簇Au20的原子坐标、原子数目和团簇能量，因此要通过原子坐标和原子数目来预测金团簇能量，就需要一种描述方法将随机生成的结构信息表征成数值向量的模式，同时还要保证原始数据不能丢失，利用库伦矩阵和特征值提取转换成向量以满足机器学习算法，然后利用K近邻回归模型、随机森林回归模型、LightGBM回归模型算法对金团簇能量进行预测，通过MSE评价指标选取最优算法。最后利用粒子群优化算法与其结合搜索和预测出金团簇Au20的全局最优结构并画出图形。</p><h3 id="5-1-2数据处理4"><a href="#5-1-2数据处理4" class="headerlink" title="5.1.2数据处理4"></a>5.1.2数据处理4</h3><h3 id="5-1-3金团簇能量预测模型的建立与求解5"><a href="#5-1-3金团簇能量预测模型的建立与求解5" class="headerlink" title="5.1.3金团簇能量预测模型的建立与求解5"></a>5.1.3金团簇能量预测模型的建立与求解5</h3><h4 id="5-1-3-1-K近邻回归模型的建立与求解"><a href="#5-1-3-1-K近邻回归模型的建立与求解" class="headerlink" title="5.1.3.1 K近邻回归模型的建立与求解"></a>5.1.3.1 K近邻回归模型的建立与求解</h4><h4 id="5-1-3-2随机森林回归模型的建立与求解"><a href="#5-1-3-2随机森林回归模型的建立与求解" class="headerlink" title="5.1.3.2随机森林回归模型的建立与求解"></a>5.1.3.2随机森林回归模型的建立与求解</h4><p>随机森林算法是Breiman[3]提出的群体分类模型的一种，能有效分析非线性、共线性和具有交互作用数据，在变量和数据的使用上进行随机化生成很多树，随机产生样本及节点变量，使得随机森林中的每一个棵树都不尽相关，进行bootstrap抽样,在原始训练样本集N中多次有放回地随机抽取n个新的训练样本集，生成n个分类树组成的随机森林，得到模型最优时的森林，当出现新样本时随机森林中的每一个树分别进行判断。<br>通过Python使用sklearn库调用随机森林回归算法进行金团簇能量预测，将在数据处理中得到的32×1维的特征向量作为特征变量，金团簇Au20能量作为目标变量，划分80%的训练集和20%的测试集进行求解。在sklearn中直接调用maen_squared_error( )函数计算MSE为0.458028，模型运行时间为2.342937秒。<br>随机森林回归模型使用便捷，特征无须做过多变换，具有较高精度，模型并行训练快；但结果不容易解释。</p><h4 id="5-1-3-3-LightGBM回归模型的建立与求解"><a href="#5-1-3-3-LightGBM回归模型的建立与求解" class="headerlink" title="5.1.3.3 LightGBM回归模型的建立与求解"></a>5.1.3.3 LightGBM回归模型的建立与求解</h4><p>LightGBM(Light Gradient Boosting Machine)是微软亚洲研究所DMYK团队的一个开源的算法，李淑锦, 嵇晓佳[4]认为LGB回归模型基于直方图进行计算获得更高的速度和更高的效率，占用更少的内存，支持并行计算，并且由于缩减了训练时间因此可以进行大数据处理。LGB回归模型在计算时会将浮点型数值转化成离散型数值，从而生成了一个直方图。并且在图中累计离散数值统计量，降低占用的内存来找最佳分割点，算法流程图如图1.3所示。</p><p><img src="https://img-blog.csdnimg.cn/20210531205211766.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1ODMyMDUw,size_16,color_FFFFFF,t_70" alt="图1.3 LightGBM模型训练预测流程图"><br>通过Python调用LightGBM回归算法进行金团簇能量预测，将在数据处理中得到的32×1维的特征向量作为特征变量，金团簇Au20能量作为目标变量，划分80%的训练集和20%的测试集进行求解。计算MSE为0.364445，模型运行时间为12.187506秒。发现LightGBM回归模型精度高，但训练时间长，模型复杂。</p><h4 id="5-1-3-4金团簇能量预测模型的选取"><a href="#5-1-3-4金团簇能量预测模型的选取" class="headerlink" title="5.1.3.4金团簇能量预测模型的选取"></a>5.1.3.4金团簇能量预测模型的选取</h4><p>将K近邻回归模型、随机森林回归模型和LightGBM回归模型预测准确率进行对比，如图1.4所示。<img src="https://img-blog.csdnimg.cn/20210531205316859.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1ODMyMDUw,size_16,color_FFFFFF,t_70" alt="图1.4 3种模型预测准确率"><br>K近邻回归模型在三种模型中MSE最大，精确度较低，故在随机森林回归模型和LightGBM回归模型中进行选取，又比较算法的时间开销如表1.1所示<br>表1.1 算法时间开销</p><table><thead><tr><th>算法</th><th>运行时间&#x2F;ms</th></tr></thead><tbody><tr><td>KNeighbors</td><td>96.31</td></tr><tr><td>RandomForest</td><td>2342.94</td></tr><tr><td>LightGBM</td><td>12187.51</td></tr></tbody></table><p>综合考虑，选取LightGBM回归模型作为金团簇能量预测的模型。</p><h3 id="5-1-4基于LightGBM回归模型的粒子群优化算法的建立与求解7"><a href="#5-1-4基于LightGBM回归模型的粒子群优化算法的建立与求解7" class="headerlink" title="5.1.4基于LightGBM回归模型的粒子群优化算法的建立与求解7"></a>5.1.4基于LightGBM回归模型的粒子群优化算法的建立与求解7</h3><h2 id="5-2-问题二：金团簇不同结构异构体的产生和Au32的全局最优结构的预测10"><a href="#5-2-问题二：金团簇不同结构异构体的产生和Au32的全局最优结构的预测10" class="headerlink" title="5.2 问题二：金团簇不同结构异构体的产生和Au32的全局最优结构的预测10"></a>5.2 问题二：金团簇不同结构异构体的产生和Au32的全局最优结构的预测10</h2><h3 id="5-2-1求解思路10"><a href="#5-2-1求解思路10" class="headerlink" title="5.2.1求解思路10"></a>5.2.1求解思路10</h3><h3 id="5-2-2基于Monte-Carlo方法和L-J势函数的异构体Au32的生成10"><a href="#5-2-2基于Monte-Carlo方法和L-J势函数的异构体Au32的生成10" class="headerlink" title="5.2.2基于Monte Carlo方法和L-J势函数的异构体Au32的生成10"></a>5.2.2基于Monte Carlo方法和L-J势函数的异构体Au32的生成10</h3><h3 id="5-2-3基于LightGBM回归模型的粒子群优化算法的Au32最优结构预测与稳定性分析12"><a href="#5-2-3基于LightGBM回归模型的粒子群优化算法的Au32最优结构预测与稳定性分析12" class="headerlink" title="5.2.3基于LightGBM回归模型的粒子群优化算法的Au32最优结构预测与稳定性分析12"></a>5.2.3基于LightGBM回归模型的粒子群优化算法的Au32最优结构预测与稳定性分析12</h3><h2 id="5-3-问题三：硼团簇能量预测模型的建立和B45-全局最优结构的预测13"><a href="#5-3-问题三：硼团簇能量预测模型的建立和B45-全局最优结构的预测13" class="headerlink" title="5.3 问题三：硼团簇能量预测模型的建立和B45-全局最优结构的预测13"></a>5.3 问题三：硼团簇能量预测模型的建立和B45-全局最优结构的预测13</h2><h3 id="5-3-1求解思路13"><a href="#5-3-1求解思路13" class="headerlink" title="5.3.1求解思路13"></a>5.3.1求解思路13</h3><p>首先，根据金团簇Au20的结构，通过Monte Carlo方法和L-J势函数模拟生成异构体Au32的结构，重新训练LightGBM回归模型，然后利用基于LightGBM回归的粒子群优化算法预测出全局最优结构。通过分析团簇的对称性以及平均键合能、一级解离能和二级解离能分析其稳定性[5]。</p><h3 id="5-3-2数据处理14"><a href="#5-3-2数据处理14" class="headerlink" title="5.3.2数据处理14"></a>5.3.2数据处理14</h3><h3 id="5-3-3硼团簇能量预测模型的建立与求解14"><a href="#5-3-3硼团簇能量预测模型的建立与求解14" class="headerlink" title="5.3.3硼团簇能量预测模型的建立与求解14"></a>5.3.3硼团簇能量预测模型的建立与求解14</h3><h3 id="5-3-4基于随机森林回归模型的粒子群优化算法的建立与求解15"><a href="#5-3-4基于随机森林回归模型的粒子群优化算法的建立与求解15" class="headerlink" title="5.3.4基于随机森林回归模型的粒子群优化算法的建立与求解15"></a>5.3.4基于随机森林回归模型的粒子群优化算法的建立与求解15</h3><h2 id="5-4-问题四：硼团簇不同结构异构体的产生和B40-的全局最优结构的预测17"><a href="#5-4-问题四：硼团簇不同结构异构体的产生和B40-的全局最优结构的预测17" class="headerlink" title="5.4 问题四：硼团簇不同结构异构体的产生和B40-的全局最优结构的预测17"></a>5.4 问题四：硼团簇不同结构异构体的产生和B40-的全局最优结构的预测17</h2><h3 id="5-4-1求解思路17"><a href="#5-4-1求解思路17" class="headerlink" title="5.4.1求解思路17"></a>5.4.1求解思路17</h3><p>通过Python编程首先对硼团簇B45-的坐标通过排列组合列出40个坐标所有情形共有 个，然后根据L-J势能函数计算所有情形的势能，取势能最低的作为B40-的坐标。最后通过B40-的坐标训练随机森林回归模型，利用基于随机森林回归模型的粒子群优化算法找到硼团簇B40-的全局最优结构并画出图形。通过分析团簇的对称性以及平均键合能、一级解离能和二级解离能分析其稳定性。</p><h3 id="5-4-2基于随机森林回归模型的粒子群优化算法的B40-最优结构预测与稳定性分析17"><a href="#5-4-2基于随机森林回归模型的粒子群优化算法的B40-最优结构预测与稳定性分析17" class="headerlink" title="5.4.2基于随机森林回归模型的粒子群优化算法的B40-最优结构预测与稳定性分析17"></a>5.4.2基于随机森林回归模型的粒子群优化算法的B40-最优结构预测与稳定性分析17</h3><h1 id="六、模型评价与改进18"><a href="#六、模型评价与改进18" class="headerlink" title="六、模型评价与改进18"></a>六、模型评价与改进18</h1><p>对于问题一：问题一中选取了K近邻回归模型、随机森林回归模型、LightGBM回归模型对金团簇能量进行预测，随机森林回归模型和LightGBM回归模型准确度较高，运行时间较短，加快了粒子群优化算法搜索金团簇Au20的最优结构的速度。对于问题一只选取了三种机器学习模型而且并没有进行调参，对此增加了多层神经网络和支持向量回归模型并进行参数调优，发现LightGBM回归模型精确度最高为0.347896且运行速度较快。并对粒子群优化算法种群数和迭代次数扩大在其中加入金属对称性的约束条件，发现找到的最优结构更好能量更低。<br>对于问题二：在产生金团簇异构体时采取的是L-J势函数，对此进行改进采取LJ+AT势能函数发现产生的异构体更稳定，预测的最优结构对应的能量更低。<br>对于问题三、问题四：采取的是随机森林回归模型和LightGBM回归模型做比较选取对此进行改进，将随机森林回归模型和LightGBM回归模型进行融合发现效果更好。因为预测向量中的每个值都接近于真实值时，才能保证在进行局部优化或全局搜索时的方向和真实情况是一致的。所以建立算法置信度模型，置信度定义为预测误差小于给定允许误差的点所占的比例，这个比例越大，表明算法越可靠，从结果看在准确度方面是可行的。</p><h1 id="七、参考文献19"><a href="#七、参考文献19" class="headerlink" title="七、参考文献19"></a>七、参考文献19</h1><h1 id="八、附录20"><a href="#八、附录20" class="headerlink" title="八、附录20"></a>八、附录20</h1><p><strong>第一题：</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python">read_file_1.py:<br><span class="hljs-keyword">import</span> numpy<br><span class="hljs-keyword">from</span> scipy.spatial.distance <span class="hljs-keyword">import</span> cdist<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_xyz_comment</span>(<span class="hljs-params">path</span>):<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(path, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        <span class="hljs-keyword">for</span> i, line <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(f):<br>            <span class="hljs-keyword">if</span>(i==<span class="hljs-number">1</span>):<br>                comment=<span class="hljs-built_in">float</span>(line)<br>    <span class="hljs-keyword">return</span> comment<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_xyz_coords</span>(<span class="hljs-params">path</span>):<br>    elements = []<br>    coords = []<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(path, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>        <span class="hljs-keyword">for</span> i, line <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(f):<br>            <span class="hljs-keyword">if</span> i &lt; <span class="hljs-number">2</span>:<br>                <span class="hljs-keyword">continue</span><br>            ele, x, y, z = line.strip().split()<br>            point = [<span class="hljs-built_in">float</span>(x), <span class="hljs-built_in">float</span>(y), <span class="hljs-built_in">float</span>(z)]<br>            elements.append(ele)<br>            coords.append(point)<br>    <span class="hljs-keyword">return</span> coords<br><br><span class="hljs-comment">#计算库伦矩阵</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_coulomb_matrix</span>(<span class="hljs-params">numbers, coords, alpha=<span class="hljs-number">1</span>, use_decay=<span class="hljs-literal">False</span></span>):<br>......<br></code></pre></td></tr></table></figure><h1 id="未完待续"><a href="#未完待续" class="headerlink" title="未完待续"></a>未完待续</h1><h1 id="官方优秀论文"><a href="#官方优秀论文" class="headerlink" title="官方优秀论文"></a>官方优秀论文</h1><p>链接：<a href="https://pan.baidu.com/s/1ytLtH2cqSnmD9DrWZ2QS-g">https://pan.baidu.com/s/1ytLtH2cqSnmD9DrWZ2QS-g</a><br>提取码：yhzj</p>]]></content>
    
    
    <categories>
      
      <category>数学建模</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数学建模</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>“华为杯”第十八届中国研究生数学建模竞赛D题：抗乳腺癌候选药物的优化建模(一等奖）</title>
    <link href="/2022/05/19/%E2%80%9C%E5%8D%8E%E4%B8%BA%E6%9D%AF%E2%80%9D%E7%AC%AC%E5%8D%81%E5%85%AB%E5%B1%8A%E4%B8%AD%E5%9B%BD%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9BD%E9%A2%98%EF%BC%9A%E6%8A%97%E4%B9%B3%E8%85%BA%E7%99%8C%E5%80%99%E9%80%89%E8%8D%AF%E7%89%A9%E7%9A%84%E4%BC%98%E5%8C%96%E5%BB%BA%E6%A8%A1(%E4%B8%80%E7%AD%89%E5%A5%96%EF%BC%89/"/>
    <url>/2022/05/19/%E2%80%9C%E5%8D%8E%E4%B8%BA%E6%9D%AF%E2%80%9D%E7%AC%AC%E5%8D%81%E5%85%AB%E5%B1%8A%E4%B8%AD%E5%9B%BD%E7%A0%94%E7%A9%B6%E7%94%9F%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E7%AB%9E%E8%B5%9BD%E9%A2%98%EF%BC%9A%E6%8A%97%E4%B9%B3%E8%85%BA%E7%99%8C%E5%80%99%E9%80%89%E8%8D%AF%E7%89%A9%E7%9A%84%E4%BC%98%E5%8C%96%E5%BB%BA%E6%A8%A1(%E4%B8%80%E7%AD%89%E5%A5%96%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<p>听了一等奖的学习交流会议，发现一等奖的思路都是差不多的，有一些有生物化学方面基础的可能对这方面的补充更多一些，计算机专业的对模型方面补充更多一些。有一组数模提名的队伍把答辩ppt和论文都分享了，受益匪浅。以下是github地址：<br><a href="https://github.com/QInzhengk/Math-Model-and-Machine-Learning">https://github.com/QInzhengk/Math-Model-and-Machine-Learning</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzI5MTY1MzU1Mg==&mid=2247487303&idx=1&sn=a2bdb7260d6508655e5da4366817744a&scene=19#wechat_redirect">微信公众号：数学建模与人工智能</a></p><h1 id="摘-要"><a href="#摘-要" class="headerlink" title="摘       要"></a>摘       要</h1><p>乳腺癌是目前世界上最常见，致死率较高的癌症之一。在寻找抗乳腺癌候选药物时，需同时保证化合物的生物活性和药代动力学性质和安全性。本文采用数据挖掘技术，研究了抗乳腺癌候选药物的优化建模问题。<br><strong>针对问题一</strong>，首先对所有化合物的分子描述符进行数据处理，进行缺失值和重复值检查，经检查，未发现缺失值和重复值。假设附件一和附件二的数据是对分子化合物的真实情况记录，未对异常值进行处理。之后剔除了分子描述符所在列是唯一值的列。经处理后，描述符数量由729个减少到504个。考虑到变量的取值特征，本文将504个分子描述符变量分为连续型变量（物理化学性质）和离散型变量（拓扑结构特征）两部分，分别运用相关分析和方差选择的方法，选择了与生物活性存在相关关系较强的100个连续型和55个离散型分子描述符。对这155个自变量与PIC50值建立LightGBM回归模型，并且对自变量的贡献度进行排序，找到前23个显著影响化合物生物活性的因素。考虑到这23个自变量之间可能存在多重共线性，为保证变量有较高的解释程度，计算自变量之间的相关系数，剔除自变量之间相关性较高的变量，最终得到对生物活性最具显著影响的20个分子描述符变量。最后对选取的变量计算MIC和Spearman值，结果表明，选取的变量之间相关关系较弱，具有很好的独立性。同时，选取的20个变量在化学意义上具有很好的可解释性，说明20个变量的选取是合理的。<br><strong>针对问题二</strong>，本文选择了两种模型进行对比，分别采用了随机森林和LightGBM回归模型。选取问题一得到的20个分子描述符变量，首先采用KDE分布图对比了训练集和测试集中特征变量的分布情况，剔除了数据集中分布不一致的特征变量。考虑到数据的离散性和连续性，以及自变量和因变量之间可能存在非线性关系，而且数据集较小，容易过拟合，所以本文选择随机森林和LightGBM做回归，并结合了K折交叉检验法。最后对比两组模型的误差评价指标MAE、MSE和拟合系数R2，结果显示LightGBM模型要优于随机森林方法，最终选取LightGBM方法对化合物IC50值和pIC50值进行定量预测。<br><strong>针对问题三</strong>，选取问题一得到的20个分子描述符变量对化合物的ADMET性质构建分类预测模型，本文使用了DNN和LightGBM分类模型。使用DNN模型对标准化的数据做分类预测，LightGBM使用原数据做分类预测，最后对两个模型的结果求平均，最终得到预测结果。其中DNN网络选用Sigmoid激活函数，使用优化算法Adam加快收敛速度。为了防止过拟合，使用dropout方法对数据进行训练。考虑到样本不平衡问题，使用LightGBM模型中的subsample参数进行处理。对ADMET测试集进行预测，得到预测结果。模型评价指标选取AUC指标，五个分类模型的值均在0.9以上，说明模型拟合较好。<br><strong>针对问题四</strong>，结合问题一、二、三，选取问题一得到的对生物活性具有显著影响的20个分子描述符特征变量，使用问题二的回归模型和问题三的分类模型，结合粒子群优化算法，进行问题求解。首先，为保证化合物的生物活性，以IC50最小（即pIC50最大）为目标函数。同时需要对ADMET性质进行约束，以保证至少三个较好的性质为约束条件。通过基于LightGBM模型的粒子群优化算法，对特征变量的取值范围进行搜索优化，最终获得相应取值范围。</p><p><strong>关键词：分子描述符，特征选择，LightGBM模型，DNN模型，粒子群优化算法</strong></p><h1 id="1-问题重述"><a href="#1-问题重述" class="headerlink" title="1. 问题重述"></a>1. 问题重述</h1><h2 id="1-1-问题背景"><a href="#1-1-问题背景" class="headerlink" title="1.1 问题背景"></a>1.1 问题背景</h2><p>乳腺癌是目前世界上最常见，致死率较高的癌症之一。ERα被认为是治疗乳腺癌的重要靶标，能够拮抗ERα活性的化合物可能是治疗乳腺癌的候选药物。比如，临床治疗乳腺癌的经典药物他莫昔芬和雷诺昔芬就是ERα拮抗剂。<br>在药物研发中，为了节约时间和成本，通常采用建立化合物活性预测模型的方法来筛选潜在活性化合物。以一系列分子结构描述符作为自变量，化合物的生物活性值作为因变量，构建化合物的定量结构-活性关系（Quantitative Structure-Activity Relationship, QSAR）模型，然后使用该模型预测具有更好生物活性的新化合物分子，或者指导已有活性化合物的结构优化。一个化合物想要成为候选药物，除了需要具备良好的生物活性（此处指抗乳腺癌活性）外，还需要在人体内具备良好的药代动力学性质和安全性，合称为ADMET（Absorption吸收、Distribution分布、Metabolism代谢、Excretion排泄、Toxicity毒性）性质。<br>根据提供的ERα拮抗剂信息（1974个化合物样本，每个样本都有729个分子描述符变量，1个生物活性数据，5个ADMET性质数据），构建化合物生物活性的定量预测模型和ADMET性质的分类预测模型，进而为优化ERα拮抗剂的生物活性和ADMET性质服务。</p><h2 id="1-2-问题重述"><a href="#1-2-问题重述" class="headerlink" title="1.2 问题重述"></a>1.2 问题重述</h2><p>基于上述研究背景，本文需研究和解决以下问题：<br><strong>问题一 筛选分子描述符</strong><br>根据文件“Molecular_Descriptor.xlsx”和“ERα_activity.xlsx”提供的数据，针对1974个化合物的729个分子描述符进行变量选择，根据变量对生物活性影响的重要性进行排序，并给出前20个对生物活性最具有显著影响的分子描述符（即变量），并请详细说明分子描述符筛选过程及其合理性。<br><strong>问题二 生物活性定量预测</strong><br>在问题一的基础上，选择不超过20个分子描述符变量，构建化合物对ERα生物活性的定量预测模型。使用构建的预测模型，对文件“ERα_activity.xlsx”的test表中的50个化合物进行IC50值和对应的pIC50值预测。<br><strong>问题三 ADMET性质分类预测</strong><br>利用文件“Molecular_Descriptor.xlsx”提供的729个分子描述符，针对文件“ADMET.xlsx”中提供的1974个化合物的ADMET数据，分别构建化合物的Caco-2、CYP3A4、hERG、HOB、MN的分类预测模型。然后使用所构建的5个分类预测模型，对文件“ADMET.xlsx”的test表中的50个化合物进行相应的预测。<br><strong>问题四 寻找分子描述符取值范围</strong><br>寻找并阐述化合物的哪些分子描述符，以及这些分子描述符在什么取值或者处于什么取值范围时，能够使化合物对抑制ERα具有更好的生物活性，同时具有更好的ADMET性质（给定的五个ADMET性质中，至少三个性质较好）。</p><h1 id="2-模型假设"><a href="#2-模型假设" class="headerlink" title="2. 模型假设"></a>2. 模型假设</h1><p>假设 1：所有样本的数据记录均为化合物的真实值、不存在录入误差，数据处理步骤正确；<br>假设 2：影响抗乳腺癌候选药物生物活性的因素只与729个分子描述符有关；<br>假设 3：在寻找分子描述符范围时认为所提出的预测模型结果准确。</p><h1 id="3-符号说明"><a href="#3-符号说明" class="headerlink" title="3. 符号说明"></a>3. 符号说明</h1><p>本文涉及符号较多，因此选择了一部分重要符号列出在下表。其他符号在文中均有说明。<br><img src="https://img-blog.csdnimg.cn/ddef7c3f8bbb4213abcf5c18502cdac7.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAcXE3NDIyMzQ5ODQ=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="符号说明"></p><h1 id="4-问题一-筛选最具显著影响描述符"><a href="#4-问题一-筛选最具显著影响描述符" class="headerlink" title="4. 问题一 筛选最具显著影响描述符"></a>4. 问题一 筛选最具显著影响描述符</h1><h2 id="4-1-问题分析"><a href="#4-1-问题分析" class="headerlink" title="4.1 问题分析"></a>4.1 问题分析</h2><p> 根据文件“Molecular_Descriptor.xlsx”和“ERα_activity.xlsx”提供的数据，针对1974个化合物的729个分子描述符进行变量选择。根据附件“分子描述符含义解释.xlsx”的解释，可以看出分子描述符被分为54类，变量之间是存在相关性或独立性的。本题的思路流程如图所示：<br><img src="https://img-blog.csdnimg.cn/0adcada5bb294ef0a4a5de2eee77162a.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAcXE3NDIyMzQ5ODQ=,size_16,color_FFFFFF,t_70,g_se,x_16" alt="图 1问题一思路流程图"><br>针对729个分子描述符，本文首先希望对其进行降维操作，剔除最不相关的变量，挑选出一部分具有代表性和独立性性的变量。本文的难点在于：（1）各自变量（生物活性）和因变量（分子描述符）之间具有高度非线性关系，判定因、自变量相关程度较为困难。而且，分子描述符中包括了物理化学性质（如分子量，LogP等），拓扑结构特征（如氢键供体数量，氢键受体数量等），本文认为不能同时对这些变量进行操作。同时为了问题二和问题四的解决，选择的变量必须是原有变量，这是特征选取问题，无法使用较为常规的特征提取方法；（2）由于变量过多，变量与变量之间可能存在相互强耦连的关系，故选取变量的独立性问题较难处理。<br>针对难点（1），变量的选择问题，筛选具有代表性的变量。首先，筛除变量中最具一般性的描述符。分子描述符分为组成描述符、分子性质描述符、拓扑描述符、几何描述符等，本文认为可以将其分为两类分别处理。本文将自变量分为连续变量和离散变量，分别对其进行初步选择。特征选择为从给定的特征中直接选择若干重要特征，所选取的变量必须是客观的，非负矩阵分析、主成分分析、独立成分分析等不适用于此问题。故最后采用LightGBM算法获取到各变量对生物活性贡献度的排名，依此实现对选取变量代表性的判断。<br>针对难点（2），变量的独立性问题，根据LightGBM得到分子描述符的贡献度排名后，对前25个变量进行多重共线性处理，从高度相关的自变量中进行筛除，来保证最后变量间的独立性。<br>最后，本文对得到的最具显著影响的变量进行合理性评价。</p><h2 id="4-2-变量初步筛选"><a href="#4-2-变量初步筛选" class="headerlink" title="4.2 变量初步筛选"></a>4.2 变量初步筛选</h2><h3 id="4-2-1-数据处理"><a href="#4-2-1-数据处理" class="headerlink" title="4.2.1 数据处理"></a>4.2.1 数据处理</h3><p>对附件“Molecular_Descriptor.xlsx”中的数据进行缺失值检查，未发现数据缺失。针对异常值问题，本文选择不对异常值处理，考虑到所给数据是记录的化合物分子描述符的真实值，直接在此基础上进行数据挖掘能够保留最真是可信的信息。</p><h3 id="4-2-2-变量的初步筛选"><a href="#4-2-2-变量的初步筛选" class="headerlink" title="4.2.2 变量的初步筛选"></a>4.2.2 变量的初步筛选</h3><p>首先，本文对729列分子描述数据进行了唯一值检查，并剔除了所在列为唯一值的变量。本文认为所在列为唯一值的分子描述对于化合物是一般性质，不具有代表性，所以进行了剔除。经过唯一值检查后，变量由729个缩减为504个。考虑到变量的连续性和离散性，本文对504个变量进行了分类，分别进行处理。下图绘制了IC50的直方图和QQ图，验证其近似服从正态分布：<br><img src="https://img-blog.csdnimg.cn/6b81fde6bded4b7f95a3684f563b913f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAcXE3NDIyMzQ5ODQ=,size_15,color_FFFFFF,t_70,g_se,x_16" alt="图 2 pIC50的直方图和QQ-图"><br>本文认为在样本集上如果当前特征基本上都差异不大，因此可以认为这个特征对区分样本贡献不大，因此可以在选择特征过程中可以将其去掉。针对离散型变量，采用了方差选择方法，从中选择了50个变量。对于连续型变量，采用相关分析的方法，选择了100个连续变量。最初步筛选后得到150个变量。<br><strong>（1）方差选择法</strong><br>方差法，要先计算各个特征的方差，然后根据阈值，选择方差大于阈值的特征。一组常数的方差为0，数据的变化越小，则方差越小。设定方差阀值，若特征的方差小于阈值，则代表该特征的发散性太弱，对于因变量几乎没有影响，可以舍弃。<br><strong>（2）Pearson相关系数法</strong><br>对特征变量的相关性进行分析，可以发现特征变量和目标变量及特征变量之间的关系，计算100个连续自变量和因变量之间的相关性系数。两个变量之间的皮尔逊相关系数定义为两个变量之间的协方差和标准差的商：</p><h2 id="4-3-LightGBM算法——变量重要性排序9"><a href="#4-3-LightGBM算法——变量重要性排序9" class="headerlink" title="4.3 LightGBM算法——变量重要性排序9"></a>4.3 LightGBM算法——变量重要性排序9</h2><h2 id="4-4-多重线性分析10"><a href="#4-4-多重线性分析10" class="headerlink" title="4.4 多重线性分析10"></a>4.4 多重线性分析10</h2><h2 id="4-5-合理性解释12"><a href="#4-5-合理性解释12" class="headerlink" title="4.5 合理性解释12"></a>4.5 合理性解释12</h2><h1 id="5-问题二-生物活性定量预测12"><a href="#5-问题二-生物活性定量预测12" class="headerlink" title="5. 问题二 生物活性定量预测12"></a>5. 问题二 生物活性定量预测12</h1><h2 id="5-1-问题分析13"><a href="#5-1-问题分析13" class="headerlink" title="5.1 问题分析13"></a>5.1 问题分析13</h2><h2 id="5-2-生物活性定量预测模型建立14"><a href="#5-2-生物活性定量预测模型建立14" class="headerlink" title="5.2 生物活性定量预测模型建立14"></a>5.2 生物活性定量预测模型建立14</h2><h3 id="5-2-1-基于KDE分布图剔除特征变量14"><a href="#5-2-1-基于KDE分布图剔除特征变量14" class="headerlink" title="5.2.1 基于KDE分布图剔除特征变量14"></a>5.2.1 基于KDE分布图剔除特征变量14</h3><h3 id="5-2-2-K折交叉验证法15"><a href="#5-2-2-K折交叉验证法15" class="headerlink" title="5.2.2 K折交叉验证法15"></a>5.2.2 K折交叉验证法15</h3><h3 id="5-2-3-随机森林算法实现16"><a href="#5-2-3-随机森林算法实现16" class="headerlink" title="5.2.3 随机森林算法实现16"></a>5.2.3 随机森林算法实现16</h3><h3 id="5-2-4-基于LightGBM的回归模型17"><a href="#5-2-4-基于LightGBM的回归模型17" class="headerlink" title="5.2.4 基于LightGBM的回归模型17"></a>5.2.4 基于LightGBM的回归模型17</h3><h3 id="5-2-5-模型比较18"><a href="#5-2-5-模型比较18" class="headerlink" title="5.2.5 模型比较18"></a>5.2.5 模型比较18</h3><h2 id="5-3-预测结果与分析19"><a href="#5-3-预测结果与分析19" class="headerlink" title="5.3 预测结果与分析19"></a>5.3 预测结果与分析19</h2><h1 id="6-问题三-ADMET性质分类预测21"><a href="#6-问题三-ADMET性质分类预测21" class="headerlink" title="6. 问题三 ADMET性质分类预测21"></a>6. 问题三 ADMET性质分类预测21</h1><h2 id="6-1-问题分析21"><a href="#6-1-问题分析21" class="headerlink" title="6.1 问题分析21"></a>6.1 问题分析21</h2><h2 id="6-2-数据处理22"><a href="#6-2-数据处理22" class="headerlink" title="6.2 数据处理22"></a>6.2 数据处理22</h2><h3 id="6-2-1-一般性检验22"><a href="#6-2-1-一般性检验22" class="headerlink" title="6.2.1 一般性检验22"></a>6.2.1 一般性检验22</h3><h3 id="6-2-2-数据标准化22"><a href="#6-2-2-数据标准化22" class="headerlink" title="6.2.2 数据标准化22"></a>6.2.2 数据标准化22</h3><h2 id="6-3-ADMET性质分类预测模型建立23"><a href="#6-3-ADMET性质分类预测模型建立23" class="headerlink" title="6.3 ADMET性质分类预测模型建立23"></a>6.3 ADMET性质分类预测模型建立23</h2><h3 id="6-3-1-DNN基本原理23"><a href="#6-3-1-DNN基本原理23" class="headerlink" title="6.3.1 DNN基本原理23"></a>6.3.1 DNN基本原理23</h3><h3 id="6-3-2-DNN模型设计24"><a href="#6-3-2-DNN模型设计24" class="headerlink" title="6.3.2 DNN模型设计24"></a>6.3.2 DNN模型设计24</h3><h3 id="6-3-3-基于LightGBM的分类模型27"><a href="#6-3-3-基于LightGBM的分类模型27" class="headerlink" title="6.3.3 基于LightGBM的分类模型27"></a>6.3.3 基于LightGBM的分类模型27</h3><h3 id="6-3-4-ADMET性质分类模型的建立28"><a href="#6-3-4-ADMET性质分类模型的建立28" class="headerlink" title="6.3.4 ADMET性质分类模型的建立28"></a>6.3.4 ADMET性质分类模型的建立28</h3><h2 id="6-4-分类结果与分析28"><a href="#6-4-分类结果与分析28" class="headerlink" title="6.4 分类结果与分析28"></a>6.4 分类结果与分析28</h2><h1 id="7-问题四-分子描述符寻找及取值范围32"><a href="#7-问题四-分子描述符寻找及取值范围32" class="headerlink" title="7. 问题四 分子描述符寻找及取值范围32"></a>7. 问题四 分子描述符寻找及取值范围32</h1><h2 id="7-1-问题分析32"><a href="#7-1-问题分析32" class="headerlink" title="7.1 问题分析32"></a>7.1 问题分析32</h2><h2 id="7-2-选择分子描述符的优化模型建立33"><a href="#7-2-选择分子描述符的优化模型建立33" class="headerlink" title="7.2 选择分子描述符的优化模型建立33"></a>7.2 选择分子描述符的优化模型建立33</h2><h3 id="7-2-1-粒子群算法33"><a href="#7-2-1-粒子群算法33" class="headerlink" title="7.2.1 粒子群算法33"></a>7.2.1 粒子群算法33</h3><h3 id="7-2-2-优化目标及条件设定35"><a href="#7-2-2-优化目标及条件设定35" class="headerlink" title="7.2.2 优化目标及条件设定35"></a>7.2.2 优化目标及条件设定35</h3><h3 id="7-2-3-模型参数设定36"><a href="#7-2-3-模型参数设定36" class="headerlink" title="7.2.3 模型参数设定36"></a>7.2.3 模型参数设定36</h3><h2 id="7-3-结果与分析37"><a href="#7-3-结果与分析37" class="headerlink" title="7.3 结果与分析37"></a>7.3 结果与分析37</h2><h1 id="8-模型的评价与改进38"><a href="#8-模型的评价与改进38" class="headerlink" title="8.模型的评价与改进38"></a>8.模型的评价与改进38</h1><h1 id="9-参考文献39"><a href="#9-参考文献39" class="headerlink" title="9. 参考文献39"></a>9. 参考文献39</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><code class="hljs python">问题一 python程序变量筛选<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns<br><span class="hljs-keyword">from</span> scipy <span class="hljs-keyword">import</span> stats<br><span class="hljs-keyword">from</span> sklearn.feature_selection <span class="hljs-keyword">import</span> VarianceThreshold<br><br><span class="hljs-comment">#%%</span><br><br>ADMET_training=pd.read_excel(<span class="hljs-string">r&#x27;C:\Users\Administrator\project\huaweibeiD\ADMET.xlsx&#x27;</span>,sheet_name=<span class="hljs-string">&#x27;training&#x27;</span>)<br>ADMET_test=pd.read_excel(<span class="hljs-string">r&#x27;C:\Users\Administrator\project\huaweibeiD\ADMET.xlsx&#x27;</span>,sheet_name=<span class="hljs-string">&#x27;test&#x27;</span>)<br>ADMET_training.head()<br><span class="hljs-comment">#ADMET_test.head()</span><br><br><span class="hljs-comment">#%%</span><br><br>ER_activity_training=pd.read_excel(<span class="hljs-string">r&#x27;C:\Users\Administrator\project\huaweibeiD\ERα_activity.xlsx&#x27;</span>,sheet_name=<span class="hljs-string">&#x27;training&#x27;</span>)<br>ER_activity_test=pd.read_excel(<span class="hljs-string">r&#x27;C:\Users\Administrator\project\huaweibeiD\ERα_activity.xlsx&#x27;</span>,sheet_name=<span class="hljs-string">&#x27;test&#x27;</span>)<br>ER_activity_training.head()<br><span class="hljs-comment">#ER_activity_test.head()</span><br><br><span class="hljs-comment">#%%</span><br><br>Molecular_Descriptor_training=pd.read_excel(<span class="hljs-string">r&#x27;C:\Users\Administrator\project\huaweibeiD\Molecular_Descriptor.xlsx&#x27;</span>,sheet_name=<span class="hljs-string">&#x27;training&#x27;</span>)<br>Molecular_Descriptor_test=pd.read_excel(<span class="hljs-string">r&#x27;C:\Users\Administrator\project\huaweibeiD\Molecular_Descriptor.xlsx&#x27;</span>,sheet_name=<span class="hljs-string">&#x27;test&#x27;</span>)<br>Molecular_Descriptor_training.head()<br><span class="hljs-comment">#Molecular_Descriptor_test.head()</span><br><br><span class="hljs-comment">#%%</span><br><br>Summary=pd.read_excel(<span class="hljs-string">r&#x27;C:\Users\Administrator\project\huaweibeiD\分子描述符含义解释.xlsx&#x27;</span>,sheet_name=<span class="hljs-string">&#x27;Summary&#x27;</span>)<br>Detailed=pd.read_excel(<span class="hljs-string">r&#x27;C:\Users\Administrator\project\huaweibeiD\分子描述符含义解释.xlsx&#x27;</span>,sheet_name=<span class="hljs-string">&#x27;Detailed&#x27;</span>)<br><br><span class="hljs-comment">#%%</span><br><br><span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> Molecular_Descriptor_training.columns:<br>    <span class="hljs-comment">#nunique() 方法用于获取某列中所有唯一值的数量，</span><br>    <span class="hljs-comment">#dropna 默认参数设置为True，即在计算唯一值时排除了NULL值。    </span><br>    <span class="hljs-keyword">if</span> Molecular_Descriptor_training[col].nunique(dropna=<span class="hljs-literal">False</span>)==<span class="hljs-number">1</span>:<br>        <span class="hljs-keyword">del</span> Molecular_Descriptor_training[col]<br>    <span class="hljs-comment"># 去掉只有一种类别的 columns</span><br><span class="hljs-built_in">len</span>(Molecular_Descriptor_training.columns)<br><span class="hljs-comment">#729-&gt;504</span><br><br><span class="hljs-comment">#%%</span><br><br><span class="hljs-literal">True</span> <span class="hljs-keyword">in</span> Molecular_Descriptor_training.isna().<span class="hljs-built_in">sum</span>()!=<span class="hljs-number">0</span><br><span class="hljs-comment">#False：数据没有缺失值</span><br><br><span class="hljs-comment">#%%</span><br><br>Molecular_ER = pd.concat([Molecular_Descriptor_training, ER_activity_training[:]], axis=<span class="hljs-number">1</span>)<br><span class="hljs-keyword">del</span> Molecular_ER[<span class="hljs-string">&#x27;SMILES&#x27;</span>]<br><span class="hljs-keyword">del</span> Molecular_ER[<span class="hljs-string">&#x27;IC50_nM&#x27;</span>]<br>Molecular_ER<br><br><span class="hljs-comment">#%%</span><br><br><span class="hljs-comment">#pIC50直方图和QQ图</span><br>plt.figure(figsize=(<span class="hljs-number">10</span>,<span class="hljs-number">5</span>),dpi=<span class="hljs-number">400</span>)<br>ax=plt.subplot(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>)<br>sns.distplot(Molecular_ER[<span class="hljs-string">&#x27;pIC50&#x27;</span>],fit=stats.norm)<br>ax=plt.subplot(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>)<br>res=stats.probplot(Molecular_ER[<span class="hljs-string">&#x27;pIC50&#x27;</span>],plot=plt)<br>plt.savefig(<span class="hljs-string">&#x27;pic50_QQ.png&#x27;</span>)<br><br><span class="hljs-comment">#%%</span><br><br><span class="hljs-comment">#离散特征</span><br>Discrete_features=[]<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> Detailed[<span class="hljs-string">&#x27;Descriptor&#x27;</span>]:<br>    <span class="hljs-keyword">if</span> i[<span class="hljs-number">0</span>]==<span class="hljs-string">&#x27;n&#x27;</span> <span class="hljs-keyword">and</span> i <span class="hljs-keyword">in</span> Molecular_Descriptor_training.columns:<br>        Discrete_features.append(i)<br><span class="hljs-comment">#Molecular_Discrete_training=Molecular_Descriptor_training[Discrete_features]</span><br><span class="hljs-comment">#连续特征</span><br>Continuous_features=[col <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> Molecular_Descriptor_training.columns <span class="hljs-keyword">if</span> col <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> Discrete_features+[<span class="hljs-string">&#x27;SMILES&#x27;</span>]] <br><span class="hljs-comment">#Molecular_Continuous_training=Molecular_Descriptor_training[Continuous_features]</span><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(Discrete_features),<span class="hljs-built_in">len</span>(Continuous_features))<br>......<br></code></pre></td></tr></table></figure><h1 id="未完待续（更新时间：2022-x2F-05-x2F-14）"><a href="#未完待续（更新时间：2022-x2F-05-x2F-14）" class="headerlink" title="未完待续（更新时间：2022&#x2F;05&#x2F;14）"></a>未完待续（更新时间：2022&#x2F;05&#x2F;14）</h1>]]></content>
    
    
    <categories>
      
      <category>数学建模</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数学建模</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
